"""
Modul pentru analiza avansatÄƒ Ã®n 2 runde cu LLM worker.
"""
import logging
import json
import re
from sqlmodel import Session, text
from typing import Dict, Any, List, Tuple
from ..settings_manager import settings_manager

logger = logging.getLogger(__name__)

class TwoRoundLLMAnalyzer:
    """
    OrchestreazÄƒ analiza Ã®n 2 runde:
    Round 1: LLM genereazÄƒ cod filtrare
    Round 2: LLM analizeazÄƒ datele filtrate
    """

    def __init__(self, session: Session):
        self.session = session

    async def analyze(self, user_query: str) -> Dict[str, Any]:
        """
        Procesul complet de analizÄƒ Ã®n 4 paÈ™i.

        Args:
            user_query: Ãntrebarea utilizatorului

        Returns:
            Dict cu rezultate finale
        """
        try:
            logger.info(f"--- START TWO-ROUND ANALYSIS: {user_query[:50]}... ---")

            # PAS 1 + 2: Generare È™i execuÈ›ie cod filtrare
            filtered_data = await self._round_1_filter_data(user_query)

            if not filtered_data:
                return {
                    'success': False,
                    'error': 'Nu s-au gÄƒsit date relevante dupÄƒ filtrare (0 rezultate).'
                }

            logger.info(f"[ROUND 1] Extras {len(filtered_data)} cazuri relevante")

            # PAS 3 + 4: Analiza datelor filtrate
            final_result = await self._round_2_analyze_data(user_query, filtered_data)

            return final_result

        except Exception as e:
            logger.error(f"[TWO-ROUND] Eroare criticÄƒ: {e}", exc_info=True)
            return {
                'success': False,
                'error': str(e)
            }

    async def _round_1_filter_data(self, user_query: str) -> List[Dict]:
        """
        ROUND 1: LLM genereazÄƒ cod Python pentru filtrare, apoi Ã®l rulÄƒm.

        Returns:
            Lista de cazuri filtrate
        """
        from ..lib.network_file_saver import NetworkFileSaver

        # Construire PROMPT 1
        prompt_round_1 = self._build_filter_prompt(user_query)

        logger.info("[ROUND 1] Trimitem prompt pentru generare cod filtrare...")

        # ObÈ›inem setÄƒrile de reÈ›ea
        retea_host = settings_manager.get_value('setari_retea', 'retea_host', '')
        retea_folder = settings_manager.get_value('setari_retea', 'retea_folder_partajat', '')

        # Salvare prompt Ã®n reÈ›ea
        success, message, saved_path = NetworkFileSaver.save_to_network(
            content=prompt_round_1,
            host=retea_host,
            shared_folder=retea_folder,
            subfolder=''
        )

        if not success:
            raise RuntimeError(f"Eroare salvare prompt Round 1: {message}")

        # Polling pentru rÄƒspuns
        poll_success, poll_content, response_path = await NetworkFileSaver.poll_for_response(
            saved_path=saved_path,
            timeout_seconds=600, # 10 minute timeout
            poll_interval=10
        )

        if not poll_success:
            raise RuntimeError(f"Timeout Round 1: {poll_content}")

        # Parsare JSON cu cod Python
        logger.info("[ROUND 1] Primim rÄƒspuns... parsÄƒm codul...")

        try:
            code_response = self._parse_json_response(poll_content)
            filter_code = code_response.get('python_code', '')

            if not filter_code:
                raise ValueError("RÄƒspunsul JSON nu conÈ›ine cheia 'python_code'")

        except Exception as e:
            logger.error(f"Eroare parsare rÄƒspuns Round 1: {e}")
            logger.error(f"ConÈ›inut primit: {poll_content}")
            raise ValueError(f"LLM a returnat un rÄƒspuns invalid Ã®n Round 1: {e}")

        # Cleanup fiÈ™ier rÄƒspuns
        NetworkFileSaver.delete_response_file(response_path)

        # ExecuÈ›ie cod filtrare
        logger.info("[ROUND 1] ExecutÄƒm codul de filtrare...")

        filtered_data = self._execute_filter_code(filter_code)

        return filtered_data

    async def _round_2_analyze_data(
        self,
        user_query: str,
        filtered_data: List[Dict]
    ) -> Dict[str, Any]:
        """
        ROUND 2: Trimitem datele filtrate cÄƒtre LLM pentru analizÄƒ finalÄƒ.

        Returns:
            Rezultatul final Ã®n format JSON
        """
        from ..lib.network_file_saver import NetworkFileSaver

        # 1. Extragere cÃ¢mpuri relevante
        relevant_data = self._extract_relevant_fields(user_query, filtered_data)

        # 2. Validare È™i truncare pentru a respecta limita de 30k caractere
        truncated_data, metadata = self._validate_and_truncate_data(relevant_data, user_query, max_chars=30000)

        logger.info(f"[ROUND 2] Trimitem {len(truncated_data)}/{len(filtered_data)} cazuri (dupÄƒ optimizare)")
        logger.info(f"[ROUND 2] Prompt estimat: {metadata['estimated_prompt_size']} caractere")

        # 3. Construire PROMPT 2 optimizat
        prompt_round_2 = self._build_analysis_prompt(user_query, truncated_data, metadata)

        logger.info(f"[ROUND 2] Trimitem {len(filtered_data)} cazuri pentru analizÄƒ...")

        # ObÈ›inem setÄƒrile de reÈ›ea
        retea_host = settings_manager.get_value('setari_retea', 'retea_host', '')
        retea_folder = settings_manager.get_value('setari_retea', 'retea_folder_partajat', '')

        # Salvare prompt Ã®n reÈ›ea
        success, message, saved_path = NetworkFileSaver.save_to_network(
            content=prompt_round_2,
            host=retea_host,
            shared_folder=retea_folder,
            subfolder=''
        )

        if not success:
            raise RuntimeError(f"Eroare salvare prompt Round 2: {message}")

        # Polling pentru rÄƒspuns
        poll_success, poll_content, response_path = await NetworkFileSaver.poll_for_response(
            saved_path=saved_path,
            timeout_seconds=600,
            poll_interval=10
        )

        if not poll_success:
            raise RuntimeError(f"Timeout Round 2: {poll_content}")

        # Parsare JSON cu rezultate
        logger.info("[ROUND 2] Primim analiza finalÄƒ...")

        try:
            analysis_result = self._parse_json_response(poll_content)
        except Exception as e:
            logger.error(f"Eroare parsare rÄƒspuns Round 2: {e}")
            logger.error(f"ConÈ›inut primit: {poll_content}")
            raise ValueError(f"LLM a returnat un rÄƒspuns invalid Ã®n Round 2: {e}")

        # Cleanup
        NetworkFileSaver.delete_response_file(response_path)

        return {
            'success': True,
            'results': analysis_result.get('results', {}),
            'interpretation': analysis_result.get('interpretation', ''),
            'charts': analysis_result.get('charts', []),
            'cases_analyzed': len(filtered_data),
            'cases_sent_to_llm': len(truncated_data),
            'prompt_metadata': metadata
        }

    def _build_filter_prompt(self, user_query: str) -> str:
        """ConstruieÈ™te promptul pentru ROUND 1 (generare cod filtrare)."""

        prompt = f"""===================================================================================
ğŸ”¬ ROUND 1: GENERARE COD PYTHON PENTRU FILTRARE DATE
===================================================================================
Tu eÈ™ti un Senior Python & SQL Developer specializat Ã®n optimizarea query-urilor pe baze de date juridice PostgreSQL.

=================================================================================== ğŸ“‹ TASK-UL UTILIZATORULUI
{user_query}

=================================================================================== ğŸ¯ MISIUNEA TA (ROUND 1)
GenereazÄƒ cod Python care sÄƒ FILTREZE È™i sÄƒ EXTRAGÄ‚ **DOAR CÃ‚MPURILE STRICT NECESARE** din baza de date PostgreSQL pentru task-ul de mai sus.

âš ï¸ IMPORTANT: NU trebuie sÄƒ faci analiza statisticÄƒ acum! Doar FILTREAZÄ‚ datele!
Analiza se va face Ã®n ROUND 2, dupÄƒ ce datele sunt extrase.

=================================================================================== ğŸ“Š SCHEMA BAZEI DE DATE (PostgreSQL)

Tabel: blocuri
CREATE TABLE blocuri (
    id INTEGER PRIMARY KEY,
    obj JSONB  -- ConÈ›ine 16+ cÃ¢mpuri juridice
);

CÃ¢mpuri disponibile Ã®n obj (JSONB):
1. materie (string) - "Penal", "Civil"
2. obiect (string) - "Omor", "Furt calificat"
3. solutia (string) - SoluÈ›ia instanÈ›ei cu pedepse/amenzi
4. considerente_speta (string) - Motivarea instanÈ›ei
5. argumente_instanta (string) - Argumentele instanÈ›ei
6. text_individualizare (string) - CircumstanÈ›e individualizare pedeapsÄƒ
7. data_solutiei (string/date) - Data pronunÈ›Äƒrii
8. tip_speta (string) - "Apel", "Recurs"
9. parte (string) - "Reclamant", "Inculpat"
10. text_situatia_de_fapt (string) - Faptele cauzei
... È™i alte 6+ cÃ¢mpuri

=================================================================================== ğŸš¨ REGULI CRITICE - CITEÈ˜TE CU ATENÈšIE!

âŒ NU FACE NICIODATÄ‚ ASA:
```sql
SELECT id, obj FROM blocuri WHERE ...
```
**DE CE E GREÈ˜IT**: ReturneazÄƒ TOATE cele 16+ cÃ¢mpuri din obj, cÃ¢nd ai nevoie doar de 3-5!
Acest lucru creeazÄƒ un prompt URIAÈ˜ care depÄƒÈ™eÈ™te limita de context!

âœ… FACE ÃNTOTDEAUNA ASA:
```sql
SELECT
  id,
  obj->>'obiect' as obiect,
  obj->>'materie' as materie,
  obj->>'solutia' as solutie
FROM blocuri WHERE ...
```
**DE CE E CORECT**: Extrage DOAR cÃ¢mpurile necesare pentru task. Prompt mic, eficient!

=================================================================================== ğŸ“ GHID PAS-CU-PAS PENTRU GENERAREA QUERY-ULUI

**PASUL 1**: AnalizeazÄƒ task-ul utilizatorului È™i identificÄƒ ce tip de date Ã®i trebuie:
- Durate pedepse â†’ obiect, materie, text_individualizare, solutia
- Amenzi â†’ obiect, materie, solutia, considerente_speta
- TendinÈ›e temporale â†’ obiect, materie, solutia, data_solutiei
- Motive/argumentare â†’ obiect, materie, considerente_speta, argumente_instanta

**PASUL 2**: ConstruieÈ™te SELECT cu DOAR cÃ¢mpurile identificate:
```sql
SELECT
  id,                                    -- Ãntotdeauna include ID
  obj->>'camp1' as camp1,                -- CÃ¢mp relevant 1
  obj->>'camp2' as camp2,                -- CÃ¢mp relevant 2
  obj->>'camp3' as camp3                 -- CÃ¢mp relevant 3
FROM blocuri b
```

**PASUL 3**: AdaugÄƒ filtre WHERE inteligente pentru a gÄƒsi DOAR cazurile relevante:
- FoloseÈ™te pattern matching pentru valori numerice: `obj->>'solutia' ~ '\\d+\\s*ani'`
- FiltreazÄƒ dupÄƒ materie: `obj->>'materie' ILIKE '%penal%'`
- FiltreazÄƒ dupÄƒ obiect: `obj->>'obiect' ILIKE '%omor%'`

**PASUL 4**: AdaugÄƒ LIMIT responsabil (100-250 cazuri max)

=================================================================================== ğŸ“š EXEMPLE CONCRETE

**Exemplu 1: "Care este durata medie a pedepselor pentru omor?"**

âŒ GREÈ˜IT:
```sql
SELECT id, obj FROM blocuri
WHERE obj->>'materie' ILIKE '%penal%'
LIMIT 200
```
ReturneazÄƒ TOT: 16+ cÃ¢mpuri Ã— 200 cazuri = PREA MULT!

âœ… CORECT:
```sql
SELECT
  id,
  obj->>'obiect' as obiect,
  obj->>'materie' as materie,
  obj->>'text_individualizare' as individualizare,
  obj->>'solutia' as solutie
FROM blocuri b
WHERE obj->>'materie' ILIKE '%penal%'
  AND obj->>'obiect' ILIKE '%omor%'
  AND (obj->>'solutia' ~ '\\d+\\s*(ani|luni)'
       OR obj->>'text_individualizare' ~ '\\d+\\s*(ani|luni)')
LIMIT 150
```
ReturneazÄƒ DOAR 5 cÃ¢mpuri Ã— 150 cazuri = OPTIM!

**IMPORTANT**: Include ÃNTOTDEAUNA 'text_individualizare' cÃ¢nd cauÈ›i pedepse,
deoarece uneori cÃ¢mpul 'solutia' poate fi null, dar pedeapsa se aflÄƒ Ã®n
secÈ›iunea de individualizare!

**Exemplu 2: "AnalizeazÄƒ amenzile pentru furt calificat"**

âŒ GREÈ˜IT:
```sql
SELECT id, obj FROM blocuri
WHERE obj->>'obiect' ILIKE '%furt%'
LIMIT 300
```

âœ… CORECT:
```sql
SELECT
  id,
  obj->>'obiect' as obiect,
  obj->>'materie' as materie,
  obj->>'solutia' as solutie,
  obj->>'considerente_speta' as considerente
FROM blocuri b
WHERE obj->>'obiect' ILIKE '%furt%calificat%'
  AND obj->>'solutia' ~ '\\d+(\\.\\d+)?\\s*lei'
LIMIT 200
```

**Exemplu 3: "EvoluÈ›ia pedepselor Ã®n ultimii 5 ani"**

âœ… CORECT:
```sql
SELECT
  id,
  obj->>'obiect' as obiect,
  obj->>'materie' as materie,
  obj->>'solutia' as solutie,
  obj->>'data_solutiei' as data_solutiei
FROM blocuri b
WHERE obj->>'data_solutiei' IS NOT NULL
  AND obj->>'data_solutiei' >= '2019-01-01'
  AND obj->>'solutia' ~ '\\d+\\s*(ani|luni)'
ORDER BY obj->>'data_solutiei' DESC
LIMIT 250
```

=================================================================================== ğŸ¯ PATTERN-URI REGEX UTILE

Pentru filtrare precisÄƒ Ã®n WHERE:
- Durate: `~ '\\d+\\s*(ani|luni|zile)'`
- Amenzi: `~ '\\d+(\\.\\d+)?\\s*(lei|RON)'`
- Numere generale: `~ '\\d+'`
- Date: `~ '\\d{{4}}-\\d{{2}}-\\d{{2}}'`

=================================================================================== âœ… CHECKLIST ÃNAINTE DE RÄ‚SPUNS

VerificÄƒ cÄƒ query-ul tÄƒu:
- [ ] NU foloseÈ™te `SELECT id, obj FROM blocuri`
- [ ] FoloseÈ™te `SELECT id, obj->>'camp1' as camp1, obj->>'camp2' as camp2, ...`
- [ ] Include DOAR 3-7 cÃ¢mpuri relevante pentru task
- [ ] Are filtre WHERE inteligente cu pattern matching
- [ ] Are LIMIT Ã®ntre 100-250
- [ ] CautÄƒ Ã®n secÈ›iuni specifice (solutia, individualizare, considerente)

=================================================================================== ğŸ“¤ FORMAT RÄ‚SPUNS - JSON OBLIGATORIU

{{
  "python_code": "def filter_data(session):\\n    from sqlmodel import text\\n    query = text(\\\"\\\"\\\"\\n        SELECT \\n          id,\\n          obj->>'obiect' as obiect,\\n          obj->>'materie' as materie,\\n          obj->>'solutia' as solutie\\n        FROM blocuri b\\n        WHERE obj->>'materie' ILIKE '%penal%'\\n          AND obj->>'solutia' ~ '\\\\d+\\\\s*ani'\\n        LIMIT 150\\n    \\\"\\\"\\\")\\n    return session.execute(query).mappings().all()",
  "description": "Extrage cazuri penale cu pedepse Ã®n ani, folosind doar 4 cÃ¢mpuri relevante",
  "expected_result_count": 150,
  "filters_applied": ["materie ILIKE '%penal%'", "pattern matching pe solutia", "LIMIT 150"],
  "fields_selected": ["id", "obiect", "materie", "solutia"],
  "rationale": "Pentru analiza duratelor, am selectat doar cÃ¢mpurile esenÈ›iale: obiect, materie È™i solutia (care conÈ›ine pedeapsa). Nu am inclus cele 16+ cÃ¢mpuri pentru a optimiza dimensiunea rÄƒspunsului."
}}

âš ï¸ CERINÈšE OBLIGATORII:
- Nume funcÈ›ie: `filter_data(session)`
- Import `text` Ã®n interiorul funcÈ›iei
- Return: `session.execute(query).mappings().all()`
- LIMIT este OBLIGATORIU (100-250)!
- SELECT cu cÃ¢mpuri specifice (NU `SELECT id, obj`)
- Include `fields_selected` È™i `rationale` Ã®n JSON

ğŸ”¥ RÄ‚SPUNDE DOAR CU JSON (FÄ‚RÄ‚ TEXT ÃNAINTE SAU DUPÄ‚):
"""
        return prompt

    def _build_analysis_prompt(self, user_query: str, filtered_data: List[Dict], metadata: Dict[str, Any] = None) -> str:
        """ConstruieÈ™te promptul pentru ROUND 2 (analiza datelor filtrate)."""

        # Datele sunt deja validate È™i truncate
        data_json = json.dumps(filtered_data, indent=2, ensure_ascii=False)

        # Info despre truncare dacÄƒ existÄƒ
        truncation_info = ""
        if metadata and metadata.get('truncated', False):
            truncation_info = f"\nâš ï¸ NOTÄ‚: Din {metadata['total_cases_filtered']} cazuri filtrate, am inclus {metadata['cases_included_in_prompt']} pentru a respecta limita de context.\n"

        prompt = f"""===================================================================================
ğŸ”¬ ROUND 2: ANALIZA DATELOR FILTRATE
Tu eÈ™ti un Data Scientist È™i Analist Juridic Senior.

TASK-UL ORIGINAL AL UTILIZATORULUI: {user_query}
{truncation_info}
CONTEXT: Ãn ROUND 1, am extras {len(filtered_data)} cazuri relevante din baza de date. Acum trebuie sÄƒ ANALIZEZI aceste date È™i sÄƒ returnezi rezultate statistice.

=================================================================================== ğŸ“¦ DATELE EXTRASE ({len(filtered_data)} cazuri)
{data_json}

=================================================================================== ğŸ¯ MISIUNEA TA (ROUND 2)
AnalizeazÄƒ datele È™i genereazÄƒ statistici:

1. **Extragere valori numerice**:
   - DacÄƒ cÃ¢mpul 'solutia'/'solutie' conÈ›ine valori â†’ extrage-le
   - DacÄƒ 'solutia' este null/gol â†’ cautÄƒ Ã®n 'individualizare'/'text_individualizare'
   - Pattern-uri comune: "X ani", "X luni", "X zile", "X lei", "amenda de X lei"
   - FoloseÈ™te regex pentru extragere: r'(\d+)\s*(ani|luni|zile|lei)'

2. **CalculeazÄƒ statistici**:
   - Total cazuri analizate
   - Medie, medianÄƒ, min, max
   - DistribuÈ›ie (dacÄƒ relevanÈ›Äƒ)
   - TendinÈ›e temporale (dacÄƒ existÄƒ date)

3. **Interpretare**: RezumÄƒ descoperirile Ã®n limbaj natural

=================================================================================== ğŸš¨ REGULI CRITICE - RÄ‚SPUNS JSON OBLIGATORIU!

âŒ NU RÄ‚SPUNDE NICIODATÄ‚ CU TEXT NORMAL:
```
Analiza datelor relevÄƒ cÄƒ nu existÄƒ valori numerice...
```
**DE CE E GREÈ˜IT**: AplicaÈ›ia aÈ™teaptÄƒ JSON valid È™i va da eroare!

âœ… RÄ‚SPUNDE ÃNTOTDEAUNA CU JSON, CHIAR DACÄ‚ NU AI DATE:
```json
{{
  "results": {{
    "total_cases_analyzed": 13,
    "error": "Nu s-au gÄƒsit valori numerice Ã®n cÃ¢mpurile solutia sau individualizare",
    "data_quality_issues": ["Toate cÃ¢mpurile 'solutia' sunt null", "Nu s-au gÄƒsit pattern-uri numerice Ã®n 'individualizare'"]
  }},
  "interpretation": "Datele extrase nu conÈ›in informaÈ›ii numerice despre pedepse. Se recomandÄƒ verificarea bazei de date sau ajustarea filtrelor de extragere.",
  "charts": []
}}
```

=================================================================================== ğŸ“¤ FORMAT RÄ‚SPUNS - EXEMPLE CONCRETE

**Exemplu 1: Date valide cu pedepse**
```json
{{
  "results": {{
    "total_cases_analyzed": 87,
    "mean_sentence_years": 15.3,
    "median_sentence_years": 14.0,
    "min_sentence_years": 5,
    "max_sentence_years": 25,
    "sentence_distribution": {{"5-10 ani": 12, "10-15 ani": 45, "15-20 ani": 25, "20+ ani": 5}}
  }},
  "interpretation": "Analiza a 87 de cazuri de omor relevÄƒ o pedeapsÄƒ medie de 15.3 ani, cu majoritatea pedepselor (51.7%) Ã®n intervalul 10-15 ani. Se observÄƒ aplicarea consistentÄƒ a pedepselor Ã®n limitele legale.",
  "charts": [
    {{
      "type": "bar_chart",
      "title": "DistribuÈ›ia pedepselor",
      "data": {{"labels": ["5-10 ani", "10-15 ani", "15-20 ani", "20+ ani"], "values": [12, 45, 25, 5]}}
    }}
  ]
}}
```

**Exemplu 2: Date incomplete (cÃ¢mpuri null)**
```json
{{
  "results": {{
    "total_cases_analyzed": 13,
    "data_source": "individualizare",
    "extracted_values_count": 8,
    "mean_sentence_years": 3.2,
    "note": "CÃ¢mpul 'solutia' era null, valorile au fost extrase din 'individualizare' folosind pattern matching"
  }},
  "interpretation": "Din cele 13 cazuri de furt, s-au putut extrage 8 valori numerice din secÈ›iunea de individualizare. Pedeapsa medie este de 3.2 ani. Pentru 5 cazuri nu s-au gÄƒsit valori numerice explicite.",
  "charts": []
}}
```

**Exemplu 3: LipsÄƒ date numerice (IMPORTANT!)**
```json
{{
  "results": {{
    "total_cases_analyzed": 10,
    "error": "Extragere eÈ™uatÄƒ: nu s-au gÄƒsit valori numerice",
    "fields_checked": ["solutia", "solutie", "individualizare", "text_individualizare"],
    "suggestion": "VerificaÈ›i dacÄƒ datele conÈ›in informaÈ›ii despre pedepse Ã®n alte cÃ¢mpuri sau dacÄƒ este necesarÄƒ o filtrare mai specificÄƒ"
  }},
  "interpretation": "Analiza nu a putut identifica valori numerice Ã®n datele furnizate. CÃ¢mpurile verificate (solutia, individualizare) nu conÈ›in pattern-uri de tipul 'X ani' sau 'X lei'. Se recomandÄƒ verificarea surselor de date.",
  "charts": []
}}
```

=================================================================================== âš ï¸ CERINÈšE ABSOLUTE

1. RÄƒspunsul TREBUIE sÄƒ fie JSON valid
2. Cheia 'results' este OBLIGATORIE
3. Cheia 'interpretation' este OBLIGATORIE
4. Cheia 'charts' este OBLIGATORIE (poate fi array gol [])
5. NICIODATÄ‚ nu rÄƒspunde cu text explicativ Ã®n afara JSON-ului
6. DacÄƒ nu gÄƒseÈ™ti date â†’ returneazÄƒ JSON cu cÃ¢mpul 'error'
7. FoloseÈ™te DOAR escape-uri valide Ã®n JSON (\n, \t, \", \\)

ğŸ”¥ RÄ‚SPUNDE EXCLUSIV CU JSON (ZERO TEXT ÃNAINTE SAU DUPÄ‚):
"""
        return prompt

    def _execute_filter_code(self, python_code: str) -> List[Dict]:
        """
        ExecutÄƒ codul Python de filtrare generat de LLM.
        """
        from ..lib.python_executor import SecurePythonExecutor

        executor = SecurePythonExecutor()

        # 1. Validare cod
        try:
            executor.validate_code(python_code)
        except ValueError as e:
            raise ValueError(f"Codul generat de LLM nu este sigur: {e}")

        # 2. Wrapper pentru a injecta session-ul DB
        # Definim o funcÈ›ie wrapper care primeÈ™te session-ul curent din self.session
        # Dar SecurePythonExecutor ruleazÄƒ exec(), deci trebuie sÄƒ-i pasÄƒm session-ul cumva.
        # SoluÈ›ia: InjectÄƒm session-ul Ã®n global_scope al executorului sau folosim un closure.
        # Aici vom folosi o abordare unde codul generat foloseÈ™te 'session' care va fi disponibil Ã®n scope.

        # Codul generat este de forma:
        # def filter_data(session):
        #    ...
        #    return ...

        # Noi trebuie sÄƒ-l apelÄƒm.

        wrapper_code = f"""
{python_code}

# ExecuÈ›ie
# Variabila 'current_session' va fi injectatÄƒ Ã®n globals
filtered_results = filter_data(current_session)
"""

        # InjectÄƒm session-ul curent
        # ModificÄƒm SecurePythonExecutor sÄƒ accepte variabile extra Ã®n scope

        # HACK: Pentru a nu modifica prea mult SecurePythonExecutor acum,
        # vom face un mic bypass controlat sau Ã®l actualizÄƒm.
        # Mai bine actualizÄƒm apelul cÄƒtre executor sÄƒ suporte context custom.

        # Dar stai, SecurePythonExecutor.execute_code_with_db_access foloseÈ™te un `exec` simplu.
        # Trebuie sÄƒ-i dÄƒm session-ul.

        # Rescriem un pic logica de execuÈ›ie localÄƒ aici pentru simplitate,
        # sau instanÈ›iem executorul È™i Ã®i dÄƒm ce trebuie.

        # SÄƒ folosim executorul definit anterior, dar trebuie sÄƒ-i dÄƒm session-ul.
        # Executorul definit Ã®n pasul anterior nu primea session ca parametru la execute.
        # Voi face o micÄƒ modificare la logicÄƒ:

        try:
            # PregÄƒtim scope-ul
            local_scope = {}
            global_scope = {
                'text': text,
                'Session': Session,
                'List': List,
                'Dict': Dict,
                'Any': Any,
                'current_session': self.session # InjectÄƒm sesiunea curentÄƒ!
            }

            # ExecutÄƒm
            exec(wrapper_code, global_scope, local_scope)

            if 'filtered_results' in local_scope:
                raw_data = local_scope['filtered_results']
            else:
                raise RuntimeError("Codul nu a returnat 'filtered_results'")

        except Exception as e:
            raise RuntimeError(f"Eroare execuÈ›ie cod filtrare: {e}")

        # Procesare rezultate (Flatten)
        processed = []
        for row in raw_data:
            # row este un RowMapping sau dict
            # Poate conÈ›ine fie 'obj' (JSONB complet) fie cÃ¢mpuri individuale

            # DacÄƒ e RowMapping, accesÄƒm ca dict
            if hasattr(row, '_mapping'):
                row_dict = dict(row._mapping)
            else:
                row_dict = dict(row)

            # VerificÄƒm dacÄƒ avem cÃ¢mpul 'obj' (query vechi: SELECT id, obj)
            if 'obj' in row_dict:
                obj_data = row_dict.get('obj', {})

                if isinstance(obj_data, str):
                    try:
                        obj_data = json.loads(obj_data)
                    except:
                        obj_data = {}

                if not isinstance(obj_data, dict):
                    obj_data = {}

                # CombinÄƒm ID cu datele din obj
                flat_item = {
                    'id': row_dict.get('id'),
                    **obj_data
                }
            else:
                # Query nou: SELECT id, obj->>'field1' as field1, obj->>'field2' as field2
                # Deja avem cÃ¢mpurile ca È™i coloane separate
                flat_item = row_dict

            processed.append(flat_item)

        return processed

    def _parse_json_response(self, content: str) -> Dict:
        """Parse rÄƒspuns JSON de la LLM, gestionÃ¢nd potenÈ›iale markdown blocks."""
        content = content.strip()

        # EliminÄƒm markdown code blocks ```json ... ```
        if content.startswith("```"):
            # CÄƒutÄƒm primul {
            start = content.find("{")
            # CÄƒutÄƒm ultimul }
            end = content.rfind("}")
            if start != -1 and end != -1:
                content = content[start:end+1]

        # ÃncercÄƒm sÄƒ gÄƒsim JSON-ul dacÄƒ e Ã®ngropat Ã®n text
        start = content.find('{')
        end = content.rfind('}')

        if start != -1 and end != -1:
            json_str = content[start:end+1]
            return json.loads(json_str)

        raise ValueError("Nu s-a gÄƒsit JSON valid Ã®n rÄƒspuns")

    def _identify_query_type(self, query: str) -> str:
        """IdentificÄƒ tipul query-ului bazat pe cuvinte cheie."""
        query_lower = query.lower()

        # Detectare durate/pedepse
        if any(word in query_lower for word in ['durata', 'pedeapsa', 'pedepse', 'ani', 'luni', 'condamnare', 'inchisoare', 'detentie']):
            return 'durate'

        # Detectare amenzi
        elif any(word in query_lower for word in ['amenda', 'amendÄƒ', 'lei', 'suma', 'bani']):
            return 'amenzi'

        # Detectare tendinÈ›e temporale
        elif any(word in query_lower for word in ['evolutie', 'evoluÈ›ie', 'tendinta', 'tendinÈ›Äƒ', 'timp', 'crestere', 'scadere', 'perioada']):
            return 'tendinte'

        # Detectare motive/considerente
        elif any(word in query_lower for word in ['motiv', 'considerent', 'argumentare', 'justificare', 'rationament']):
            return 'motive'

        # Default: general
        else:
            return 'general'

    def _extract_relevant_fields(self, user_query: str, filtered_data: List[Dict]) -> List[Dict]:
        """Extrage doar cÃ¢mpurile relevante pentru query, reducÃ¢nd dimensiunea datelor."""

        # IdentificÄƒ tipul query-ului
        query_type = self._identify_query_type(user_query)

        logger.info(f"[EXTRAGERE] Query type identificat: {query_type}")

        # Mapping cÃ¢mpuri relevante pentru fiecare tip de query
        field_mappings = {
            'durate': ['id', 'obiect', 'materie', 'text_individualizare', 'individualizare', 'solutia', 'solutie', 'data_solutiei'],
            'amenzi': ['id', 'obiect', 'materie', 'solutia', 'solutie', 'considerente_speta', 'considerente'],
            'tendinte': ['id', 'obiect', 'materie', 'solutia', 'solutie', 'data_solutiei'],
            'motive': ['id', 'obiect', 'materie', 'considerente_speta', 'considerente', 'argumente_instanta', 'solutia', 'solutie'],
            'general': ['id', 'obiect', 'materie', 'solutia', 'solutie', 'text_individualizare', 'individualizare', 'considerente_speta']
        }

        relevant_fields = field_mappings.get(query_type, field_mappings['general'])

        # Extragere cÃ¢mpuri relevante
        result = []
        for case in filtered_data:
            filtered_case = {}
            for field in relevant_fields:
                if field in case:
                    value = case[field]
                    # TruncÄƒm textele foarte lungi (> 2000 chars) pentru a economisi spaÈ›iu
                    if isinstance(value, str) and len(value) > 2000:
                        filtered_case[field] = value[:2000] + "...[truncat]"
                    else:
                        filtered_case[field] = value

            # Include Ã®ntotdeauna ID-ul
            if 'id' not in filtered_case and 'id' in case:
                filtered_case['id'] = case['id']

            result.append(filtered_case)

        logger.info(f"[EXTRAGERE] Redus de la {len(filtered_data)} cazuri cu toate cÃ¢mpurile la {len(result)} cazuri cu cÃ¢mpuri relevante")

        return result

    def _validate_and_truncate_data(
        self,
        filtered_data: List[Dict],
        user_query: str,
        max_chars: int = 30000
    ) -> Tuple[List[Dict], Dict[str, Any]]:
        """
        ValideazÄƒ È™i truncÄƒ datele pentru a nu depÄƒÈ™i max_chars.

        Returns:
            Tuple[truncated_data, metadata]
        """

        # Construim un prompt gol pentru a estima dimensiunea de bazÄƒ
        base_prompt = f"""===================================================================================
ğŸ”¬ ROUND 2: ANALIZA DATELOR FILTRATE
Tu eÈ™ti un Data Scientist È™i Analist Juridic Senior.

TASK-UL ORIGINAL AL UTILIZATORULUI: {user_query}

CONTEXT: Ãn ROUND 1, am extras cazuri relevante din baza de date.

===================================================================================
ğŸ“¦ DATELE EXTRASE

===================================================================================
ğŸ¯ MISIUNEA TA (ROUND 2)
AnalizeazÄƒ datele de mai sus È™i genereazÄƒ:
1. Statistici descriptive (medie, medianÄƒ, etc.)
2. TendinÈ›e (evoluÈ›ie Ã®n timp)
3. CorelaÈ›ii (dacÄƒ e relevant)
4. Interpretare Ã®n limbaj natural (concluzii clare)

===================================================================================
ğŸ“¤ FORMAT RÄ‚SPUNS - JSON OBLIGATORIU
{{
  "results": {{
    "total_cases_analyzed": 87,
    "mean_sentence_years": 15.3
  }},
  "interpretation": "Analiza relevÄƒ...",
  "charts": []
}}

RÄ‚SPUNDE DOAR CU JSON:
"""

        base_size = len(base_prompt)

        # SpaÈ›iu disponibil pentru date (cu buffer de siguranÈ›Äƒ de 2000 chars)
        available_space = max_chars - base_size - 2000

        if available_space <= 0:
            logger.warning(f"[VALIDARE] Base prompt prea mare: {base_size} chars. ForÈ›Äƒm spaÈ›iu minim.")
            available_space = 5000  # Minimum absolut pentru date

        logger.info(f"[VALIDARE] SpaÈ›iu disponibil pentru date: {available_space} caractere")

        # Procesare date cu truncare progresivÄƒ
        truncated_data = []
        current_size = 0
        cases_included = 0

        for case in filtered_data:
            # Serializare caz individual
            case_json = json.dumps(case, ensure_ascii=False, separators=(',', ':'))  # Compact JSON
            case_size = len(case_json)

            # VerificÄƒm dacÄƒ mai avem spaÈ›iu
            if current_size + case_size + 10 <= available_space:  # +10 pentru separatori
                truncated_data.append(case)
                current_size += case_size + 10
                cases_included += 1
            else:
                # Nu mai avem spaÈ›iu, oprim
                logger.info(f"[VALIDARE] Truncare la {cases_included} cazuri pentru a respecta limita")
                break

        # CalculÄƒm dimensiunea finalÄƒ estimatÄƒ
        final_data_json = json.dumps(truncated_data, indent=2, ensure_ascii=False)
        final_data_size = len(final_data_json)
        estimated_total = base_size + final_data_size

        metadata = {
            'total_cases_filtered': len(filtered_data),
            'cases_included_in_prompt': cases_included,
            'base_prompt_size': base_size,
            'data_size': final_data_size,
            'estimated_prompt_size': estimated_total,
            'truncated': cases_included < len(filtered_data),
            'available_space': available_space,
            'max_chars_limit': max_chars
        }

        # Log important pentru debugging
        logger.info(f"[VALIDARE] âœ“ Prompt Round 2 validat:")
        logger.info(f"  - Cazuri incluse: {cases_included}/{len(filtered_data)}")
        logger.info(f"  - Dimensiune estimatÄƒ: {estimated_total:,} / {max_chars:,} caractere")
        logger.info(f"  - SpaÈ›iu rÄƒmas: {max_chars - estimated_total:,} caractere")

        if estimated_total > max_chars:
            logger.warning(f"[VALIDARE] âš ï¸ ATENÈšIE: Prompt estimat ({estimated_total}) depÄƒÈ™eÈ™te limita ({max_chars})!")

        return truncated_data, metadata
