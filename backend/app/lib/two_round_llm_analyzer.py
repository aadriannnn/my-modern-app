"""
Modul pentru analiza avansatÄƒ Ã®n 2 runde cu LLM worker.
"""
import logging
import json
import re
from sqlmodel import Session, text
from typing import Dict, Any, List, Tuple
from ..settings_manager import settings_manager

logger = logging.getLogger(__name__)

class TwoRoundLLMAnalyzer:
    """
    OrchestreazÄƒ analiza Ã®n 2 runde:
    Round 1: LLM genereazÄƒ cod filtrare
    Round 2: LLM analizeazÄƒ datele filtrate
    """

    def __init__(self, session: Session):
        self.session = session

    async def analyze(self, user_query: str) -> Dict[str, Any]:
        """
        Procesul complet de analizÄƒ Ã®n 4 paÈ™i.

        Args:
            user_query: Ãntrebarea utilizatorului

        Returns:
            Dict cu rezultate finale
        """
        try:
            logger.info(f"--- START TWO-ROUND ANALYSIS: {user_query[:50]}... ---")

            # PAS 1 + 2: Generare È™i execuÈ›ie cod filtrare
            filtered_data = await self._round_1_filter_data(user_query)

            if not filtered_data:
                return {
                    'success': False,
                    'error': 'Nu s-au gÄƒsit date relevante dupÄƒ filtrare (0 rezultate).'
                }

            logger.info(f"[ROUND 1] Extras {len(filtered_data)} cazuri relevante")

            # PAS 3 + 4: Analiza datelor filtrate
            final_result = await self._round_2_analyze_data(user_query, filtered_data)

            return final_result

        except Exception as e:
            logger.error(f"[TWO-ROUND] Eroare criticÄƒ: {e}", exc_info=True)
            return {
                'success': False,
                'error': str(e)
            }

    async def _round_1_filter_data(self, user_query: str) -> List[Dict]:
        """
        ROUND 1: LLM genereazÄƒ cod Python pentru filtrare, apoi Ã®l rulÄƒm.

        Returns:
            Lista de cazuri filtrate
        """
        from ..lib.network_file_saver import NetworkFileSaver

        # Construire PROMPT 1
        prompt_round_1 = self._build_filter_prompt(user_query)

        logger.info("[ROUND 1] Trimitem prompt pentru generare cod filtrare...")

        # ObÈ›inem setÄƒrile de reÈ›ea
        retea_host = settings_manager.get_value('setari_retea', 'retea_host', '')
        retea_folder = settings_manager.get_value('setari_retea', 'retea_folder_partajat', '')

        # Salvare prompt Ã®n reÈ›ea
        success, message, saved_path = NetworkFileSaver.save_to_network(
            content=prompt_round_1,
            host=retea_host,
            shared_folder=retea_folder,
            subfolder=''
        )

        if not success:
            raise RuntimeError(f"Eroare salvare prompt Round 1: {message}")

        # Polling pentru rÄƒspuns
        poll_success, poll_content, response_path = await NetworkFileSaver.poll_for_response(
            saved_path=saved_path,
            timeout_seconds=600, # 10 minute timeout
            poll_interval=10
        )

        if not poll_success:
            raise RuntimeError(f"Timeout Round 1: {poll_content}")

        # Parsare JSON cu cod Python
        logger.info("[ROUND 1] Primim rÄƒspuns... parsÄƒm codul...")

        try:
            code_response = self._parse_json_response(poll_content)
            filter_code = code_response.get('python_code', '')

            if not filter_code:
                raise ValueError("RÄƒspunsul JSON nu conÈ›ine cheia 'python_code'")

        except Exception as e:
            logger.error(f"Eroare parsare rÄƒspuns Round 1: {e}")
            logger.error(f"ConÈ›inut primit: {poll_content}")
            raise ValueError(f"LLM a returnat un rÄƒspuns invalid Ã®n Round 1: {e}")

        # Cleanup fiÈ™ier rÄƒspuns
        NetworkFileSaver.delete_response_file(response_path)

        # ExecuÈ›ie cod filtrare
        logger.info("[ROUND 1] ExecutÄƒm codul de filtrare...")

        filtered_data = self._execute_filter_code(filter_code)

        return filtered_data

    async def _round_2_analyze_data(
        self,
        user_query: str,
        filtered_data: List[Dict]
    ) -> Dict[str, Any]:
        """
        ROUND 2: Trimitem datele filtrate cÄƒtre LLM pentru analizÄƒ finalÄƒ.

        Returns:
            Rezultatul final Ã®n format JSON
        """
        from ..lib.network_file_saver import NetworkFileSaver

        # Construire PROMPT 2
        prompt_round_2 = self._build_analysis_prompt(user_query, filtered_data)

        logger.info(f"[ROUND 2] Trimitem {len(filtered_data)} cazuri pentru analizÄƒ...")

        # ObÈ›inem setÄƒrile de reÈ›ea
        retea_host = settings_manager.get_value('setari_retea', 'retea_host', '')
        retea_folder = settings_manager.get_value('setari_retea', 'retea_folder_partajat', '')

        # Salvare prompt Ã®n reÈ›ea
        success, message, saved_path = NetworkFileSaver.save_to_network(
            content=prompt_round_2,
            host=retea_host,
            shared_folder=retea_folder,
            subfolder=''
        )

        if not success:
            raise RuntimeError(f"Eroare salvare prompt Round 2: {message}")

        # Polling pentru rÄƒspuns
        poll_success, poll_content, response_path = await NetworkFileSaver.poll_for_response(
            saved_path=saved_path,
            timeout_seconds=600,
            poll_interval=10
        )

        if not poll_success:
            raise RuntimeError(f"Timeout Round 2: {poll_content}")

        # Parsare JSON cu rezultate
        logger.info("[ROUND 2] Primim analiza finalÄƒ...")

        try:
            analysis_result = self._parse_json_response(poll_content)
        except Exception as e:
            logger.error(f"Eroare parsare rÄƒspuns Round 2: {e}")
            logger.error(f"ConÈ›inut primit: {poll_content}")
            raise ValueError(f"LLM a returnat un rÄƒspuns invalid Ã®n Round 2: {e}")

        # Cleanup
        NetworkFileSaver.delete_response_file(response_path)

        return {
            'success': True,
            'results': analysis_result.get('results', {}),
            'interpretation': analysis_result.get('interpretation', ''),
            'charts': analysis_result.get('charts', []),
            'cases_analyzed': len(filtered_data)
        }

    def _build_filter_prompt(self, user_query: str) -> str:
        """ConstruieÈ™te promptul pentru ROUND 1 (generare cod filtrare)."""

        prompt = f"""===================================================================================
ğŸ”¬ ROUND 1: GENERARE COD PYTHON PENTRU FILTRARE DATE
===================================================================================
Tu eÈ™ti un Senior Python & SQL Developer specializat Ã®n optimizarea query-urilor pe baze de date juridice PostgreSQL.

=================================================================================== ğŸ“‹ TASK-UL UTILIZATORULUI
{user_query}

=================================================================================== ğŸ¯ MISIUNEA TA (ROUND 1)
GenereazÄƒ cod Python care sÄƒ FILTREZE È™i sÄƒ EXTRAGÄ‚ DOAR datele relevante din baza de date PostgreSQL pentru task-ul de mai sus.

âš ï¸ IMPORTANT: NU trebuie sÄƒ faci analiza statisticÄƒ acum! Doar FILTREAZÄ‚ datele!
Analiza se va face Ã®n ROUND 2, dupÄƒ ce datele sunt extrase.

=================================================================================== ğŸ“Š SCHEMA COMPLETÄ‚ A BAZEI DE DATE (PostgreSQL)
Tabel principal: blocuri

StructurÄƒ tabel:
CREATE TABLE blocuri (
    id INTEGER PRIMARY KEY,
    obj JSONB,                    -- CÃ¢mp JSONB cu toate datele cazului juridic
    vector FLOAT[],               -- Vector embedding pentru cÄƒutare semanticÄƒ
    modele_speta JSONB,           -- Modele de documente relevante
    coduri_speta JSONB,           -- Articole de lege relevante
    updated_at TIMESTAMP          -- Data ultimei actualizÄƒri
);

=================================================================================== ğŸ“¦ CÃ‚MPURI DISPONIBILE ÃN obj (JSONB)
1. materie (string) - ex: "Penal", "Civil"
2. obiect (string) - ex: "Omor", "Furt calificat"
3. solutia (string) - ex: "Condamnare la 15 ani..."
4. considerente_speta (string) - Motivarea instanÈ›ei
5. argumente_instanta (string) - Argumente
6. tip_speta (string) - ex: "Apel", "Recurs"
7. parte (string) - ex: "Reclamant", "Inculpat"
8. text_individualizare (string) - CircumstanÈ›e
9. tip_act_juridic (string) - ex: "Decizie penalÄƒ"
10. denumire (string) - Titlul cazului
11. text_situatia_de_fapt / situatia_de_fapt / situatie (string) - Faptele cauzei
12. text_doctrina (string)
13. text_ce_invatam (string)
14. Rezumat_generat_de_AI_Cod (string)
15. keywords (array[string])
16. data_solutiei (string/date) - ex: "2023-11-15"

=================================================================================== ğŸ¯ INSTRUCÈšIUNI PENTRU COD FILTRARE
1. OBIECTIV: Extrage DOAR cazurile relevante (LIMIT 100-500)
2. LOGICA: FoloseÈ™te filtre SQL inteligente (WHERE clauses) pe cÃ¢mpurile JSONB.
3. FORMAT: ReturneazÄƒ Ã®ntotdeauna `SELECT id, obj FROM blocuri ...`

Exemplu logicÄƒ filtrare (Pedepse omor):
WHERE b.obj->>'materie' ILIKE '%penal%'
  AND (b.obj->>'obiect' ILIKE '%omor%' OR b.obj->>'obiect' ILIKE '%omucidere%')
  AND (b.obj->>'solutia' ~ '\\d+\\s*ani' OR b.obj->>'considerente_speta' ~ '\\d+\\s*ani')
LIMIT 300

=================================================================================== ğŸ“¤ FORMAT RÄ‚SPUNS - JSON OBLIGATORIU
RÄƒspunsul tÄƒu TREBUIE sÄƒ fie un JSON STRICT cu aceastÄƒ structurÄƒ:

{{
  "python_code": "def filter_data(session):\\n    from sqlmodel import text\\n    query = text(\\\"\\\"\\\"\\n        SELECT id, obj\\n        FROM blocuri b\\n        WHERE b.obj->>'materie' ILIKE '%penal%'\\n        LIMIT 200\\n    \\\"\\\"\\\")\\n    return session.execute(query).mappings().all()",
  "description": "Descriere filtre...",
  "expected_result_count": 200,
  "filters_applied": ["materie ILIKE '%penal%'", "LIMIT 200"]
}}

âš ï¸ ATENÈšIE:
- Nume funcÈ›ie: `filter_data(session)`
- Import `text` Ã®n interiorul funcÈ›iei
- Return: `session.execute(query).mappings().all()`
- LIMIT este OBLIGATORIU!
- JSON valid (escape la ghilimele È™i newlines)

RÄ‚SPUNDE DOAR CU JSON:
"""
        return prompt

    def _build_analysis_prompt(self, user_query: str, filtered_data: List[Dict]) -> str:
        """ConstruieÈ™te promptul pentru ROUND 2 (analiza datelor filtrate)."""

        # Serializare date filtrate Ã®n JSON
        # LimitÄƒm la 500 cazuri pentru a nu depÄƒÈ™i contextul, deÈ™i filtrarea ar trebui sÄƒ se ocupe de asta
        data_to_send = filtered_data[:500]
        data_json = json.dumps(data_to_send, indent=2, ensure_ascii=False)

        prompt = f"""===================================================================================
ğŸ”¬ ROUND 2: ANALIZA DATELOR FILTRATE
Tu eÈ™ti un Data Scientist È™i Analist Juridic Senior.

TASK-UL ORIGINAL AL UTILIZATORULUI: {user_query}

CONTEXT: Ãn ROUND 1, am extras {len(data_to_send)} cazuri relevante din baza de date. Acum trebuie sÄƒ ANALIZEZI aceste date È™i sÄƒ returnezi rezultate statistice.

=================================================================================== ğŸ“¦ DATELE EXTRASE ({len(data_to_send)} cazuri)
{data_json}

=================================================================================== ğŸ¯ MISIUNEA TA (ROUND 2)
AnalizeazÄƒ datele de mai sus È™i genereazÄƒ:
1. Statistici descriptive (medie, medianÄƒ, etc.)
2. TendinÈ›e (evoluÈ›ie Ã®n timp)
3. CorelaÈ›ii (dacÄƒ e relevant)
4. Interpretare Ã®n limbaj natural (concluzii clare)

=================================================================================== ğŸ“¤ FORMAT RÄ‚SPUNS - JSON OBLIGATORIU
{{
  "results": {{
    "total_cases_analyzed": 87,
    "mean_sentence_years": 15.3,
    "trend_by_year": {{"2019": 14.5, "2020": 15.1}},
    "statistical_significance": "..."
  }},
  "interpretation": "Analiza relevÄƒ...",
  "charts": [
    {{
      "type": "line_chart",
      "title": "EvoluÈ›ia pedepselor",
      "data": {{"labels": ["2019", "2020"], "values": [14.5, 15.1]}}
    }}
  ]
}}

RÄ‚SPUNDE DOAR CU JSON:
"""
        return prompt

    def _execute_filter_code(self, python_code: str) -> List[Dict]:
        """
        ExecutÄƒ codul Python de filtrare generat de LLM.
        """
        from ..lib.python_executor import SecurePythonExecutor

        executor = SecurePythonExecutor()

        # 1. Validare cod
        try:
            executor.validate_code(python_code)
        except ValueError as e:
            raise ValueError(f"Codul generat de LLM nu este sigur: {e}")

        # 2. Wrapper pentru a injecta session-ul DB
        # Definim o funcÈ›ie wrapper care primeÈ™te session-ul curent din self.session
        # Dar SecurePythonExecutor ruleazÄƒ exec(), deci trebuie sÄƒ-i pasÄƒm session-ul cumva.
        # SoluÈ›ia: InjectÄƒm session-ul Ã®n global_scope al executorului sau folosim un closure.
        # Aici vom folosi o abordare unde codul generat foloseÈ™te 'session' care va fi disponibil Ã®n scope.

        # Codul generat este de forma:
        # def filter_data(session):
        #    ...
        #    return ...

        # Noi trebuie sÄƒ-l apelÄƒm.

        wrapper_code = f"""
{python_code}

# ExecuÈ›ie
# Variabila 'current_session' va fi injectatÄƒ Ã®n globals
filtered_results = filter_data(current_session)
"""

        # InjectÄƒm session-ul curent
        # ModificÄƒm SecurePythonExecutor sÄƒ accepte variabile extra Ã®n scope

        # HACK: Pentru a nu modifica prea mult SecurePythonExecutor acum,
        # vom face un mic bypass controlat sau Ã®l actualizÄƒm.
        # Mai bine actualizÄƒm apelul cÄƒtre executor sÄƒ suporte context custom.

        # Dar stai, SecurePythonExecutor.execute_code_with_db_access foloseÈ™te un `exec` simplu.
        # Trebuie sÄƒ-i dÄƒm session-ul.

        # Rescriem un pic logica de execuÈ›ie localÄƒ aici pentru simplitate,
        # sau instanÈ›iem executorul È™i Ã®i dÄƒm ce trebuie.

        # SÄƒ folosim executorul definit anterior, dar trebuie sÄƒ-i dÄƒm session-ul.
        # Executorul definit Ã®n pasul anterior nu primea session ca parametru la execute.
        # Voi face o micÄƒ modificare la logicÄƒ:

        try:
            # PregÄƒtim scope-ul
            local_scope = {}
            global_scope = {
                'text': text,
                'Session': Session,
                'List': List,
                'Dict': Dict,
                'Any': Any,
                'current_session': self.session # InjectÄƒm sesiunea curentÄƒ!
            }

            # ExecutÄƒm
            exec(wrapper_code, global_scope, local_scope)

            if 'filtered_results' in local_scope:
                raw_data = local_scope['filtered_results']
            else:
                raise RuntimeError("Codul nu a returnat 'filtered_results'")

        except Exception as e:
            raise RuntimeError(f"Eroare execuÈ›ie cod filtrare: {e}")

        # Procesare rezultate (Flatten)
        processed = []
        for row in raw_data:
            # row este un RowMapping sau dict
            # row['obj'] este JSONB-ul

            # DacÄƒ e RowMapping, accesÄƒm ca dict
            if hasattr(row, '_mapping'):
                row_dict = dict(row._mapping)
            else:
                row_dict = dict(row)

            obj_data = row_dict.get('obj', {})

            if isinstance(obj_data, str):
                try:
                    obj_data = json.loads(obj_data)
                except:
                    obj_data = {}

            if not isinstance(obj_data, dict):
                obj_data = {}

            # CombinÄƒm ID cu datele din obj
            flat_item = {
                'id': row_dict.get('id'),
                **obj_data
            }
            processed.append(flat_item)

        return processed

    def _parse_json_response(self, content: str) -> Dict:
        """Parse rÄƒspuns JSON de la LLM, gestionÃ¢nd potenÈ›iale markdown blocks."""
        content = content.strip()

        # EliminÄƒm markdown code blocks ```json ... ```
        if content.startswith("```"):
            # CÄƒutÄƒm primul {
            start = content.find("{")
            # CÄƒutÄƒm ultimul }
            end = content.rfind("}")
            if start != -1 and end != -1:
                content = content[start:end+1]

        # ÃncercÄƒm sÄƒ gÄƒsim JSON-ul dacÄƒ e Ã®ngropat Ã®n text
        start = content.find('{')
        end = content.rfind('}')

        if start != -1 and end != -1:
            json_str = content[start:end+1]
            return json.loads(json_str)

        raise ValueError("Nu s-a gÄƒsit JSON valid Ã®n rÄƒspuns")
